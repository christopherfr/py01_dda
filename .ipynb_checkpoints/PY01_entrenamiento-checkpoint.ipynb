{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install pymongo\n",
    "!pip install imblearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "2XWSFGj87l5w",
    "outputId": "bcd16618-7659-440a-9920-5e9fd7904b6e"
   },
   "outputs": [],
   "source": [
    "import pymongo\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from datetime import datetime, timedelta\n",
    "from sklearn.model_selection import LeaveOneOut, StratifiedKFold, GridSearchCV\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from imblearn.over_sampling import SMOTE, RandomOverSampler\n",
    "\n",
    "def crear_dataframe_desde_mongodb():\n",
    "    cadena_conexion = ('mongodb://{nom_usuario}:{password}@{host}:{port}')\n",
    "    cadena_conexion = cadena_conexion.format(\n",
    "        nom_usuario = 'PY01_c02',\n",
    "        password = 'P4rd83XkXrTz',\n",
    "        host = '5.189.129.12',\n",
    "        port = 27017\n",
    "    )\n",
    "    client = pymongo.MongoClient(cadena_conexion)\n",
    "    db = client.PY01\n",
    "    header = [*db.PY01.find_one().keys()]\n",
    "    lista_dataset = list()\n",
    "    for doc in db.PY01.find():\n",
    "        lista_dataset.append([*doc.values()])\n",
    " \n",
    "    df = pd.DataFrame(data = lista_dataset, columns = header)\n",
    "    return df\n",
    "\n",
    "def generar_diccionario_meses():\n",
    "    return {'Enero': 1, 'Febrero': 2, 'Marzo': 3, 'Abril': 4, 'Mayo': 5, 'Junio': 6, 'Julio': 7, 'Agosto': 8, 'Setiembre': 9, 'Septiembre': 9, 'Octubre': 10, 'Noviembre': 11, 'Diciembre': 12}\n",
    "\n",
    "def generar_diccionario_dias():\n",
    "    return {'LUNES': 1, 'MONDAY': 1, 'MARTES': 2, 'TUESDAY': 2, 'MIERCOLES': 3, 'WEDNESDAY': 3, 'JUEVES': 4, 'THURSDAY': 4, 'VIERNES': 5, 'FRIDAY': 5, 'SABADO': 6, 'SATURDAY': 6, 'DOMINGO': 7, 'SUNDAY': 7}\n",
    "\n",
    "def limpiar_dataset(df):\n",
    "    dias = generar_diccionario_dias()\n",
    "    meses = generar_diccionario_meses()\n",
    "    for dia, cod in dias.items():\n",
    "        df.loc[df.dia == dia, 'dia'] = cod\n",
    "    df.dia = pd.to_numeric(df.dia)\n",
    "    \n",
    "    for mes, cod in meses.items():\n",
    "        df.loc[df.mes == mes, 'mes'] = cod\n",
    "    df.mes = pd.to_numeric(df.mes)\n",
    "    \n",
    "    return df\n",
    "\n",
    "def generar_variables(df):\n",
    "    nuevos_registros = list()\n",
    "    for row in df.itertuples():\n",
    "        cantidad = row.cantidad\n",
    "        if cantidad > 1:\n",
    "            cantidad -= 1\n",
    "            for t in range(cantidad):\n",
    "                nuevos_registros.append(row)\n",
    "\n",
    "    df = df.append(nuevos_registros, ignore_index = True).drop(labels = ['cantidad'], axis = 1)\n",
    "\n",
    "    df = pd.concat((df, pd.get_dummies(df.dia, prefix = 'dia')), axis = 1)\n",
    "    dias_presentes = df.dia.unique()\n",
    "    if 1 not in dias_presentes:\n",
    "        df = df.assign(dia_1 = 0)\n",
    "    if 2 not in dias_presentes:\n",
    "        df = df.assign(dia_2 = 0)\n",
    "    if 3 not in dias_presentes:\n",
    "        df = df.assign(dia_3 = 0)\n",
    "    if 4 not in dias_presentes:\n",
    "        df = df.assign(dia_4 = 0)\n",
    "    if 5 not in dias_presentes:\n",
    "        df = df.assign(dia_5 = 0)\n",
    "    if 6 not in dias_presentes:\n",
    "        df = df.assign(dia_6 = 0)\n",
    "    if 7 not in dias_presentes:\n",
    "        df = df.assign(dia_7 = 0)\n",
    "    df = df.assign(dia_sin = lambda x: np.sin(2 * np.pi * x.dia / 7))\n",
    "    df = df.assign(dia_cos = lambda x: np.cos(2 * np.pi * x.dia / 7))\n",
    "    \n",
    "    df = pd.concat((df, pd.get_dummies(df.mes, prefix = 'mes')), axis = 1)\n",
    "    meses_presentes = df.mes.unique()\n",
    "    if 1 not in meses_presentes:\n",
    "        df = df.assign(mes_1 = 0)\n",
    "    if 2 not in meses_presentes:\n",
    "        df = df.assign(mes_2 = 0)\n",
    "    if 3 not in meses_presentes:\n",
    "        df = df.assign(mes_3 = 0)\n",
    "    if 4 not in meses_presentes:\n",
    "        df = df.assign(mes_4 = 0)\n",
    "    if 5 not in meses_presentes:\n",
    "        df = df.assign(mes_5 = 0)\n",
    "    if 6 not in meses_presentes:\n",
    "        df = df.assign(mes_6 = 0)\n",
    "    if 7 not in meses_presentes:\n",
    "        df = df.assign(mes_7 = 0)\n",
    "    if 8 not in meses_presentes:\n",
    "        df = df.assign(mes_8 = 0)\n",
    "    if 9 not in meses_presentes:\n",
    "        df = df.assign(mes_9 = 0)\n",
    "    if 10 not in meses_presentes:\n",
    "        df = df.assign(mes_10 = 0)\n",
    "    if 11 not in meses_presentes:\n",
    "        df = df.assign(mes_11 = 0)\n",
    "    if 12 not in meses_presentes:\n",
    "        df = df.assign(mes_12 = 0)\n",
    "    df = df.assign(mes_sin = lambda x: np.sin(2 * np.pi * x.mes / 12))\n",
    "    df = df.assign(mes_cos = lambda x: np.cos(2 * np.pi * x.mes / 12))\n",
    "\n",
    "    return df[['cliente',\n",
    "               'anho',\n",
    "               'dia',\n",
    "               'dia_1','dia_2','dia_3','dia_4','dia_5','dia_6','dia_7',\n",
    "               'dia_sin','dia_cos',\n",
    "               'mes',\n",
    "               'mes_1','mes_2','mes_3','mes_4','mes_5','mes_6','mes_7','mes_8','mes_9','mes_10','mes_11','mes_12',\n",
    "               'mes_sin','mes_cos',\n",
    "               'prod']]\n",
    "\n",
    "def retirar_data_validacion(df):\n",
    "    # No hay manera de saber qué registros pertenecen a los días 10 al 14 de mayo, así que se va a considerar todo mayo como validación\n",
    "    return df[~((df.anho == '2021') & (df.mes == 5))]\n",
    "\n",
    "def corregir_dtypes_dataframe(df):\n",
    "    df.cantidad = pd.to_numeric(df.cantidad)\n",
    "    df.monto = pd.to_numeric(df.monto)\n",
    "    df.descuento = pd.to_numeric(df.descuento)\n",
    "    return df\n",
    "\n",
    "def preparar_dataset(df):\n",
    "    df = corregir_dtypes_dataframe(df)\n",
    "    df = limpiar_dataset(df)\n",
    "    df = seleccionar_clientes(df)\n",
    "    df = generar_variables(df)\n",
    "    df = retirar_data_validacion(df)\n",
    "    df = df.drop(labels = ['anho'], axis = 1)\n",
    "    return df\n",
    "\n",
    "def seleccionar_clientes(df):\n",
    "    #df_top_clientes = df[(df.cliente != 'SID1')] # & ~((df.anho == '2021') & (df.mes == 'Mayo'))\n",
    "    #df_top_clientes = df_top_clientes[['cliente', 'monto']]\n",
    "    #df_top_clientes = df_top_clientes.groupby(by = 'cliente', as_index = False).sum()\n",
    "    #df_top_clientes = df_top_clientes.sort_values(by = 'monto', ascending = False)\n",
    "    #df_top_clientes = df_top_clientes.head(round(len(df_top_clientes) * 0.2))\n",
    "    #df_top_clientes\n",
    "\n",
    "    meses = generar_diccionario_meses()\n",
    "    df_frecuencia_clientes = df[(df.cliente != 'SID1')]\n",
    "    df_frecuencia_clientes = df_frecuencia_clientes.assign(mes_numero = None)\n",
    "    #df_frecuencia_clientes.mes_numero = df_frecuencia_clientes.mes.apply(lambda x: meses.get(x))\n",
    "    df_frecuencia_clientes = df_frecuencia_clientes.assign(periodo = lambda x: pd.to_numeric(x.anho) * 100 + x.mes)\n",
    "    df_frecuencia_clientes.periodo = df_frecuencia_clientes.periodo.apply(str)\n",
    "    periodos = sorted(df_frecuencia_clientes.periodo.unique(), reverse = True)\n",
    "    df_frecuencia_clientes = pd.pivot_table(df_frecuencia_clientes[['cliente','periodo','monto']], index = 'cliente', columns = 'periodo', values = 'monto', aggfunc = np.sum, fill_value = 0)\n",
    "    df_frecuencia_clientes = df_frecuencia_clientes.assign(persistencia = '')\n",
    "    for periodo_col in periodos:\n",
    "        df_frecuencia_clientes.loc[df_frecuencia_clientes[periodo_col] > 0, periodo_col] = 1 # binarizamos\n",
    "        df_frecuencia_clientes[periodo_col] = df_frecuencia_clientes[periodo_col].apply(lambda x: str(int(x)))\n",
    "        df_frecuencia_clientes.loc[:,'persistencia'] = df_frecuencia_clientes.persistencia + df_frecuencia_clientes[periodo_col]\n",
    "\n",
    "    df_frecuencia_clientes.sort_values(by = 'persistencia', ascending = False)\n",
    "    df_frecuencia_clientes = df_frecuencia_clientes.assign(frecuencia_mensual_reciente = None)\n",
    "    for p in range(len(periodos), 0, -1):\n",
    "        df_frecuencia_clientes.frecuencia_mensual_reciente[df_frecuencia_clientes.frecuencia_mensual_reciente.isna()] = df_frecuencia_clientes[df_frecuencia_clientes.frecuencia_mensual_reciente.isna()].persistencia.apply(lambda x: p if x.startswith('1' * p) else None)\n",
    "\n",
    "    return df[df.cliente.isin(df_frecuencia_clientes[df_frecuencia_clientes.frecuencia_mensual_reciente >= 3].index)]\n",
    "\n",
    "def generar_variantes():\n",
    "    variantes = {1: ['dia','prod'],\n",
    "                 #2: ['dia_1','dia_2','dia_3','dia_4','dia_5','dia_6','dia_7','prod'],\n",
    "                 #3: ['dia_sin','dia_cos','prod'],\n",
    "                 4: ['mes','prod'],\n",
    "                 #5: ['mes_1','mes_2','mes_3','mes_4','mes_5','mes_6','mes_7','mes_8','mes_9','mes_10','mes_11','mes_12','prod'],\n",
    "                 #6: ['mes_sin','mes_cos','prod'],\n",
    "                 7: ['dia','mes','prod']}#,\n",
    "                 #8: ['dia','mes_1','mes_2','mes_3','mes_4','mes_5','mes_6','mes_7','mes_8','mes_9','mes_10','mes_11','mes_12','prod'],\n",
    "                 #9: ['dia','mes_sin','mes_cos','prod'],\n",
    "                 #10: ['dia_1','dia_2','dia_3','dia_4','dia_5','dia_6','dia_7','mes','prod'],\n",
    "                 #11: ['dia_1','dia_2','dia_3','dia_4','dia_5','dia_6','dia_7','mes_1','mes_2','mes_3','mes_4','mes_5','mes_6','mes_7','mes_8','mes_9','mes_10','mes_11','mes_12','prod'],\n",
    "                 #12: ['dia_1','dia_2','dia_3','dia_4','dia_5','dia_6','dia_7','mes_sin','mes_cos','prod'],\n",
    "                 #13: ['dia_sin','dia_cos','mes','prod'],\n",
    "                 #14: ['dia_sin','dia_cos','mes_1','mes_2','mes_3','mes_4','mes_5','mes_6','mes_7','mes_8','mes_9','mes_10','mes_11','mes_12','prod'],\n",
    "                 #15: ['dia_sin','dia_cos','mes_sin','mes_cos','prod'],\n",
    "                 #16: ['dia','dia_1','dia_2','dia_3','dia_4','dia_5','dia_6','dia_7','dia_sin','dia_cos','mes','mes_1','mes_2','mes_3','mes_4','mes_5','mes_6','mes_7','mes_8','mes_9','mes_10','mes_11','mes_12','mes_sin','mes_cos','prod']} # adición de último momento\n",
    "    return variantes\n",
    "\n",
    "def oversampling(X, y):\n",
    "    if min(y.value_counts()) == 1:\n",
    "        return RandomOverSampler().fit_resample(X, y)\n",
    "    else:\n",
    "        try:\n",
    "            return SMOTE(k_neighbors = min(*y.value_counts(), 5)).fit_resample(X, y)\n",
    "        except ValueError:\n",
    "            return SMOTE(k_neighbors = min(*y.value_counts(), 5) - 1).fit_resample(X, y)\n",
    " \n",
    "def aplicar_grid_search(X, y, modelo, params):\n",
    "    if len(X) > 20:\n",
    "        cv = StratifiedKFold(10)\n",
    "    else:\n",
    "        cv = LeaveOneOut()\n",
    "    gs = GridSearchCV(estimator = modelo,\n",
    "                      param_grid = params,\n",
    "                      cv = cv,\n",
    "                      scoring = ['accuracy','f1_weighted'],\n",
    "                      refit = 'f1_weighted',\n",
    "                      return_train_score = True,\n",
    "                      verbose = 0,\n",
    "                      n_jobs = -1)\n",
    "    gs.fit(X, y)\n",
    "    return (gs.best_estimator_,\n",
    "            dict(test_f1_weighted = gs.best_score_,\n",
    "                 train_f1_weighted = gs.cv_results_['mean_train_f1_weighted'][gs.best_index_],\n",
    "                 test_accuracy = gs.cv_results_['mean_test_accuracy'][gs.best_index_],\n",
    "                 train_accuracy = gs.cv_results_['mean_train_accuracy'][gs.best_index_]\n",
    "                )\n",
    "           )\n",
    " \n",
    "def entrenar_LR(X, y):\n",
    "    print('algoritmo LR')\n",
    "    modelo = LogisticRegression(max_iter = 1000)\n",
    "    params = dict(C = np.logspace(-6,2,9), solver = ('newton-cg','sag','saga','lbfgs'))\n",
    "    clasificador = aplicar_grid_search(X, y, modelo, params)\n",
    "    return clasificador\n",
    "\n",
    "def entrenar_SVM(X, y):\n",
    "    print('algoritmo SVM')\n",
    "    modelo = SVC()\n",
    "    params = dict(C = np.logspace(-7,2,9), gamma = np.logspace(-7,2,9))\n",
    "    clasificador = aplicar_grid_search(X, y, modelo, params)\n",
    "    return clasificador\n",
    "\n",
    "def entrenar_RF(X, y):\n",
    "    print('algoritmo RF')\n",
    "    modelo = RandomForestClassifier(n_estimators = 70)\n",
    "    params = dict(max_depth = range(3,11,2), min_samples_split = range(3,11,2))\n",
    "    clasificador = aplicar_grid_search(X, y, modelo, params)\n",
    "    return clasificador\n",
    "\n",
    "def entrenar_NB(X, y):\n",
    "    print('algoritmo NB')\n",
    "    modelo = GaussianNB()\n",
    "    params = dict(var_smoothing = np.logspace(-11,-20, 10))\n",
    "    clasificador = aplicar_grid_search(X, y, modelo, params)\n",
    "    return clasificador\n",
    "\n",
    "def entrenar_KNN(X, y):\n",
    "    print('algoritmo KNN')\n",
    "    modelo = KNeighborsClassifier()\n",
    "    params = dict(n_neighbors = range(2, 10, 3), weights = ('uniform','distance'), p = (1,2))\n",
    "    clasificador = aplicar_grid_search(X, y, modelo, params)\n",
    "    return clasificador\n",
    "\n",
    "def busqueda_mejor_variante_algoritmo_hiperparametros(producto, df_producto, criterio_ordenacion):\n",
    "    print(df_producto['prod'].value_counts())\n",
    "    df_producto.loc[df_producto['prod'] == producto, 'prod'] = 1\n",
    "    df_producto.loc[df_producto['prod'] != 1, 'prod'] = 0\n",
    "    X = df_producto.drop(labels = 'prod', axis = 1)\n",
    "    y = df_producto['prod'].astype('int')\n",
    "    X, y = oversampling(X, y)\n",
    "    print(y.value_counts())\n",
    "    mejores_clasificadores_este_producto_y_cliente = list()\n",
    "    for cod_variante, variante in sorted(generar_variantes().items(), reverse = False):\n",
    "        print('cod_variante {}'.format(cod_variante))\n",
    "        for entrenar_algoritmo in (entrenar_NB, entrenar_LR, entrenar_RF): #entrenar_SVM, entrenar_KNN, \n",
    "            mejor_clasificador, puntajes = entrenar_algoritmo(X[variante[:-1]], y)\n",
    "            mejores_clasificadores_este_producto_y_cliente.append(dict(cod_variante = cod_variante, clasificador = mejor_clasificador, puntajes = puntajes))\n",
    "    mejor_de_mejores = sorted(mejores_clasificadores_este_producto_y_cliente, key = criterio_ordenacion, reverse = True)[0]\n",
    "    return mejor_de_mejores\n",
    "\n",
    "def entrenar(df, variantes):\n",
    "    global clasificadores_por_cliente\n",
    "    criterio_ordenacion = lambda x: (x['puntajes']['test_f1_weighted'], x['puntajes']['test_accuracy'], x['puntajes']['train_f1_weighted'], x['puntajes']['train_accuracy'])\n",
    "    lista_clientes = sorted(df.cliente.unique(), key = lambda cod_cli: int(cod_cli[3:]))\n",
    "    clasificadores_por_cliente = dict()\n",
    "    for cliente in lista_clientes:\n",
    "        print('cliente {}'.format(cliente))\n",
    "        df_cliente = df[df.cliente == cliente].drop(labels = 'cliente', axis = 1)\n",
    "        lista_productos_este_cliente = sorted(df_cliente['prod'].unique(), key = lambda cod_prod: int(cod_prod[3:]))\n",
    "        n_clases = len(lista_productos_este_cliente)\n",
    "        clasificador_por_producto_este_cliente = dict()\n",
    "        if n_clases == 1:\n",
    "            continue\n",
    "        elif n_clases == 2:\n",
    "            producto_1, producto_2 = lista_productos_este_cliente\n",
    "            mejor_de_mejores = busqueda_mejor_variante_algoritmo_hiperparametros(producto_2, df_cliente, criterio_ordenacion)\n",
    "            mejor_de_mejores['clases_prod'] = {0: producto_1, 1: producto_2}\n",
    "            clasificadores_por_cliente[cliente] = dict(n_clases = n_clases, solucion = mejor_de_mejores)\n",
    "        elif n_clases > 2:\n",
    "            for producto in lista_productos_este_cliente:\n",
    "                print('producto {}'.format(producto))\n",
    "                mejor_de_mejores = busqueda_mejor_variante_algoritmo_hiperparametros(producto, df_cliente, criterio_ordenacion)\n",
    "                clasificador_por_producto_este_cliente[producto] = mejor_de_mejores\n",
    "            clasificadores_por_cliente[cliente] = dict(n_clases = n_clases, solucion = clasificador_por_producto_este_cliente)\n",
    "    return clasificadores_por_cliente\n",
    "\n",
    "def main():\n",
    "    df = crear_dataframe_desde_mongodb()\n",
    "    df = preparar_dataset(df)\n",
    "    variantes = generar_variantes()\n",
    "    c = entrenar(df, variantes)\n",
    "    return c\n",
    "\n",
    "#clasificadores_por_cliente = None\n",
    "rs = 10\n",
    "np.random.seed(rs)\n",
    "ans = main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for k,v in clasificadores_por_cliente.items():\n",
    "    print(k)\n",
    "    print(v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import pickle\n",
    "#pickle_out = open('pickles/trabajo_v2.pkl', 'wb')\n",
    "#pickle.dump(clasificadores_por_cliente, pickle_out)\n",
    "#pickle_out.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "xutkRuk5sbtY"
   },
   "outputs": [],
   "source": [
    "import pickle\n",
    "pickle_in = open('pickles/trabajo_v2.pkl', 'rb')\n",
    "clasificadores_por_cliente = pickle.load(pickle_in)\n",
    "pickle_in.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SID13\n",
      "KS_536\n",
      "SID23\n",
      "SID30\n",
      "KS_369\n",
      "SID55\n",
      "KS_415\n",
      "KS_673\n",
      "KS_675\n",
      "SID127\n",
      "KS_386\n",
      "KS_414\n",
      "KS_446\n",
      "KS_484\n",
      "KS_688\n",
      "SID170\n",
      "KS_644\n",
      "SID265\n",
      "KS_308\n",
      "KS_324\n",
      "KS_336\n",
      "KS_346\n",
      "KS_348\n",
      "KS_354\n",
      "KS_364\n",
      "KS_476\n",
      "KS_538\n",
      "KS_582\n",
      "KS_624\n",
      "KS_688\n",
      "KS_950\n",
      "KS_971\n",
      "KS_1024\n",
      "KS_1033\n",
      "SID300\n",
      "SID315\n",
      "KS_369\n",
      "SID320\n",
      "KS_653\n",
      "SID324\n",
      "SID339\n",
      "KS_324\n",
      "KS_652\n",
      "KS_654\n",
      "SID340\n",
      "KS_346\n",
      "KS_348\n",
      "KS_360\n",
      "SID357\n",
      "SID467\n",
      "KS_548\n",
      "SID474\n",
      "KS_362\n",
      "KS_366\n",
      "KS_950\n",
      "SID511\n",
      "SID517\n",
      "KS_367\n",
      "KS_939\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import f1_score\n",
    "\n",
    "df = crear_dataframe_desde_mongodb()\n",
    "df = corregir_dtypes_dataframe(df)\n",
    "df = limpiar_dataset(df)\n",
    "df = seleccionar_clientes(df)\n",
    "\n",
    "train = df[~((df.anho == '2021') & (df.mes == 5))]\n",
    "train = generar_variables(train)\n",
    "\n",
    "test = df[((df.anho == '2021') & (df.mes == 5))]\n",
    "test = generar_variables(test)\n",
    "\n",
    "clasificadores = clasificadores_por_cliente\n",
    "variantes = generar_variantes()\n",
    "\n",
    "curvas_por_cliente = dict()\n",
    "#for cliente, (cod_variante, clasificador) in clasificadores.items():\n",
    "for cliente, values in clasificadores.items():\n",
    "    #if cliente != 'SID339': continue\n",
    "    print(cliente)\n",
    "    train_cliente = train[train.cliente == cliente]\n",
    "    test_cliente = test[test.cliente == cliente]\n",
    "    curvas_por_producto = dict()\n",
    "    for producto, solucion in values['solucion'].items():\n",
    "        if producto not in test_cliente['prod'].unique(): continue\n",
    "        print(producto)\n",
    "        \n",
    "        train_cliente_producto = train_cliente.copy()\n",
    "        train_cliente_producto.loc[train_cliente_producto['prod'] == producto, 'prod'] = 1\n",
    "        train_cliente_producto.loc[train_cliente_producto['prod'] != 1, 'prod'] = 0\n",
    "        \n",
    "        test_cliente_producto = test_cliente.copy()\n",
    "        test_cliente_producto.loc[test_cliente_producto['prod'] == producto, 'prod'] = 1\n",
    "        test_cliente_producto.loc[test_cliente_producto['prod'] != 1, 'prod'] = 0\n",
    "        \n",
    "        cod_variante = solucion['cod_variante']\n",
    "        clasificador = solucion['clasificador']\n",
    "        puntajes_cv = solucion['puntajes']\n",
    "        \n",
    "        train_cliente_producto = train_cliente_producto[variantes[cod_variante]]\n",
    "        test_cliente_producto = test_cliente_producto[variantes[cod_variante]]\n",
    "        \n",
    "        X_train_cliente_producto = train_cliente_producto.drop(labels = 'prod', axis = 1)\n",
    "        y_train_cliente_producto = train_cliente_producto['prod'].astype('int')\n",
    "        X_train_cliente_producto, y_train_cliente_producto = oversampling(X_train_cliente_producto, y_train_cliente_producto)\n",
    "        train_oversampled = X_train_cliente_producto.join(y_train_cliente_producto)\n",
    "        train_oversampled_producto_0 = train_oversampled[train_oversampled['prod'] == 0]\n",
    "        train_oversampled_producto_1 = train_oversampled[train_oversampled['prod'] == 1]\n",
    "        cantidad_producto_0 = len(train_oversampled_producto_0)\n",
    "        cantidad_producto_1 = len(train_oversampled_producto_1)\n",
    "        for i in range(min(cantidad_producto_0, cantidad_producto_1)):\n",
    "            if i == 0:\n",
    "                train_resorted = train_oversampled_producto_0.iloc[[i]]\n",
    "                train_resorted = train_resorted.append(train_oversampled_producto_1.iloc[i])\n",
    "            else:\n",
    "                train_resorted = train_resorted.append(train_oversampled_producto_0.iloc[i])\n",
    "                train_resorted = train_resorted.append(train_oversampled_producto_1.iloc[i])\n",
    "\n",
    "            if (i+1) == min(cantidad_producto_0, cantidad_producto_1):\n",
    "                producto_mas_grande = np.argmax([cantidad_producto_0, cantidad_producto_1])\n",
    "                if producto_mas_grande == 0:\n",
    "                    train_resorted = train_resorted.append(train_oversampled_producto_0.iloc[i+1:])\n",
    "                elif producto_mas_grande == 1:\n",
    "                    train_resorted = train_resorted.append(train_oversampled_producto_1.iloc[i+1:])\n",
    "                break\n",
    "                \n",
    "        X_train_cliente_producto = train_resorted.drop(labels = 'prod', axis = 1)\n",
    "        y_train_cliente_producto = train_resorted['prod'].astype('int')\n",
    "            \n",
    "        X_test_cliente_producto = test_cliente_producto.drop(labels = 'prod', axis = 1)\n",
    "        y_test_cliente_producto = test_cliente_producto['prod'].astype('int')\n",
    "        #X_test_cliente_producto_os, y_test_cliente_producto_os = oversampling(X_test_cliente_producto_og, y_test_cliente_producto_og)\n",
    "\n",
    "        cantidad_training_samples = len(X_train_cliente_producto)\n",
    "        curva_aprendizaje = dict()\n",
    "        for train_samples in range(cantidad_training_samples):\n",
    "            train_samples += 1\n",
    "            if train_samples == 1: continue\n",
    "            clasificador.fit(X_train_cliente_producto.head(train_samples), y_train_cliente_producto.head(train_samples))\n",
    "            try:\n",
    "                y_train_pred = clasificador.predict(X_train_cliente_producto)\n",
    "            except ValueError as e:\n",
    "                if type(clasificador) == KNeighborsClassifier:\n",
    "                    continue\n",
    "                else:\n",
    "                    raise e\n",
    "            y_test_pred = clasificador.predict(X_test_cliente_producto)\n",
    "            #y_test_pred_os = clasificador.predict(X_test_cliente_producto_os)\n",
    "            score_train = f1_score(y_train_cliente_producto, y_train_pred, average = 'weighted')\n",
    "            score_test = f1_score(y_test_cliente_producto, y_test_pred, average = 'weighted')\n",
    "            #score_test_os = f1_score(y_test_cliente_producto_os, y_test_pred_os, average = 'weighted')\n",
    "            \n",
    "            curva_aprendizaje[train_samples] = dict(score_train = score_train, score_test = score_test) #, score_test_os = score_test_os)\n",
    "            \n",
    "        curvas_por_producto[producto] = curva_aprendizaje\n",
    "    curvas_por_cliente[cliente] = curvas_por_producto"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle_out = open('pickles/validacion_v2.pkl', 'wb')\n",
    "pickle.dump(curvas_por_cliente, pickle_out)\n",
    "pickle_out.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ahora = crear_dataframe_desde_mongodb()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "KS_302    1\n",
       "KS_308    1\n",
       "KS_324    1\n",
       "KS_346    1\n",
       "KS_386    3\n",
       "KS_456    3\n",
       "KS_458    3\n",
       "KS_476    1\n",
       "KS_496    5\n",
       "KS_536    3\n",
       "KS_538    1\n",
       "KS_542    1\n",
       "KS_548    1\n",
       "KS_586    2\n",
       "KS_616    1\n",
       "KS_644    2\n",
       "KS_676    1\n",
       "KS_708    1\n",
       "KS_720    2\n",
       "Name: prod, dtype: int64"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_ahora[df_ahora.cliente == 'SID13']['prod'].value_counts().sort_index()"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "PY01_entrenamiento.ipynb",
   "provenance": []
  },
  "instance_type": "ml.t3.medium",
  "kernelspec": {
   "display_name": "Python 3 (Data Science)",
   "language": "python",
   "name": "python3__SAGEMAKER_INTERNAL__arn:aws:sagemaker:us-east-1:081325390199:image/datascience-1.0"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
